HADOOP STUDY

MapReduce

MapReduce개념
MapReduce는 HDFS에 저장된 파일을 분산 배치 분석을 할 수 있도록 도와주는 분산 프레임워크.
개발자는 프로그래밍모델에 맞게 애플리케이션을 구현만 하면 된다.
나머지 데이터 전송, 분산 처리, 내고장성등의 복잡한 처리는 MapReduce프레임워크가 처리해준다.
MapReduce는 Map과 Reduce 두 단계로 데이터를 처리한다.

1. Map
Map 단계는 입력받은 데이터(ex - HDFS의 파일)를  Key, Value의 형태로 데이터를 분류하는 단계다.
기본적인 방식을 표현한다면 아래와 같다.
(K1, V1) -> list(K2, V2)

Ex.
입력 파일
read a book
write a book
두줄로 이루어진 txt파일.

첫번째라인, read a book -> {"read" : 1, "a" : 1, "book" : 1}
두번째라인 , write a book -> {"write" : 1, "a" : 1, "book" : 1}

2.Reduce
Map 단계에 나온 출력을 집계하는 단계입니다. 출력은 Key, Value의 형태입니다.
기본적인 방식을 표현한다면 아래와 같습니다.
(K2, list(V2)) -> (K3, list(V3))

위의 Map예제에서 이어서 보겠습니다.
Ex.
{"read" : 1, "a" : 1, "book" : 1}, {"write" : 1, "a" : 1, "book" : 1} -> {"a" : 2, "book" : 2, "read" : 1, "write" : 1}

2. Architecture
MapReduce 프레임 워크의 경우 개발자가 분석로직에만 집중할 수 있도록 해주고 다른 작업은 프레임워크에서 맡아서 해준다.
따라서 시스템 구성 및 데이터 흐름을 모르더라도 당장의 개발에 지장이 없다.
하지만 시스템 구성 및 데이터 흐름을 모르고 개발한다면 성능을 고려하지 못한 개발을 할 수 밖에 없으며 문제가 생길 경우
해결할 수 없다.

2.1 시스템 구성
MapReduce 시스템은 클라이언트, 잡트래커, 태스크트래커로 구성된다.
클라이언트 <-> 잡트래커간의 일은 클라이언트가 잡트래커에 잡 실행을 요청하면 잡트래커가 잡을 실행하여 진행상황 및 결과를 공유해준다.
잡트래커 <-> 태스크트래커간의 일은 아래에 설명한다.
먼저 잡트래커가 태스크트래커에게 태스크실행을 요청한다.
그럼 태스크 트래커는 잡트래커가 요청한 맵과 리듀스 갯수만큼 맵태스크와 리듀스태스크를 생성한다.
태스크가 생성이 되면 새로운 JVM을 구동해 태스크들을 실행한다.
잡트래커와 태스크트래커는 하트비트라는 메서드로 네트워크 통신을 하면서 태스크트래커의 상태와 작업실행정보를 주고받게된다.
만약 태스크트래커에 장애가 발생한다면  다른 대기중인 태스크트래커를 찾아서 재실행한다.

클라이언트
-사용자가 실행한 MapReduce프로그램과 하둡에서 제공하는 MapReduceAPI를 의미

잡
-클라이언트가 하둡으로 실행을 요청하는 맵리듀스 프로그램을 관리하는 작업 단위

잡트래커
-하둡클러스터에 등록된 전체 잡의 스케줄링을 관리하고 모니터링한다.
어떤 요청이 들어오면 잡을 처리하기위해 몇 개의 맵과 리듀스를 실행할지 계산한다.
이렇게 계산된 맵과 리듀스를 어떤 태스크트래커에서 실행할지 결정하고, 해당 태스크트래커에 잡을 할당한다.

태스크트래커
-사용자가 설정한 MapReduce프로그램을 실행하며, 하둡의 데이터노드에서 실행되는 데몬을 의미한다.
잡트래커의 작업을 요청받고, 잡트래커가 요청한 맵과 리듀스 개수만큼 맵태스크 및 리듀스태스크를 생성한다.
맵태스크와 리듀스태스크가 생성되면 새로운 JVM을 구동해 태스크들을 실행한다.
서버의 개수와 상관없이 여러 JVM을 실행해 데이터를 동시에 분석하므로 병렬처리작업에 문제가 없다.
