HADOOP STUDY

프로그램 실행법

./bin/hadoop jar WordCountMapReduce.jar com.naver.Main input파일 output파일

MapReduce

MapReduce개념
MapReduce는 HDFS에 저장된 파일을 분산 배치 분석을 할 수 있도록 도와주는 분산 프레임워크.
개발자는 프로그래밍모델에 맞게 애플리케이션을 구현만 하면 된다.
나머지 데이터 전송, 분산 처리, 내고장성등의 복잡한 처리는 MapReduce프레임워크가 처리해준다.
MapReduce는 Map과 Reduce 두 단계로 데이터를 처리한다.

1. Map
Map 단계는 입력받은 데이터(ex - HDFS의 파일)를  Key, Value의 형태로 데이터를 분류하는 단계다.
기본적인 방식을 표현한다면 아래와 같다.
(K1, V1) -> list(K2, V2)

Ex.
입력 파일
read a book
write a book
두줄로 이루어진 txt파일.

첫번째라인, read a book -> {"read" : 1, "a" : 1, "book" : 1}
두번째라인 , write a book -> {"write" : 1, "a" : 1, "book" : 1}

2.Reduce
Map 단계에 나온 출력을 집계하는 단계입니다. 출력은 Key, Value의 형태입니다.
기본적인 방식을 표현한다면 아래와 같습니다.
(K2, list(V2)) -> (K3, list(V3))

위의 Map예제에서 이어서 보겠습니다.
Ex.
{"read" : 1, "a" : 1, "book" : 1}, {"write" : 1, "a" : 1, "book" : 1} -> {"a" : 2, "book" : 2, "read" : 1, "write" : 1}

2. Architecture
MapReduce 프레임 워크의 경우 개발자가 분석로직에만 집중할 수 있도록 해주고 다른 작업은 프레임워크에서 맡아서 해준다.
따라서 시스템 구성 및 데이터 흐름을 모르더라도 당장의 개발에 지장이 없다.
하지만 시스템 구성 및 데이터 흐름을 모르고 개발한다면 성능을 고려하지 못한 개발을 할 수 밖에 없으며 문제가 생길 경우
해결할 수 없다.

2.1 시스템 구성
MapReduce 시스템은 클라이언트, 잡트래커, 태스크트래커로 구성된다.
클라이언트 <-> 잡트래커간의 일은 클라이언트가 잡트래커에 잡 실행을 요청하면 잡트래커가 잡을 실행하여 진행상황 및 결과를 공유해준다.
잡트래커 <-> 태스크트래커간의 일은 아래에 설명한다.
먼저 잡트래커가 태스크트래커에게 태스크실행을 요청한다.
그럼 태스크 트래커는 잡트래커가 요청한 맵과 리듀스 갯수만큼 맵태스크와 리듀스태스크를 생성한다.
태스크가 생성이 되면 새로운 JVM을 구동해 태스크들을 실행한다.
잡트래커와 태스크트래커는 하트비트라는 메서드로 네트워크 통신을 하면서 태스크트래커의 상태와 작업실행정보를 주고받게된다.
만약 태스크트래커에 장애가 발생한다면  다른 대기중인 태스크트래커를 찾아서 재실행한다.

클라이언트
-사용자가 실행한 MapReduce프로그램과 하둡에서 제공하는 MapReduceAPI를 의미

잡
-클라이언트가 하둡으로 실행을 요청하는 맵리듀스 프로그램을 관리하는 작업 단위

잡트래커
-하둡클러스터에 등록된 전체 잡의 스케줄링을 관리하고 모니터링한다.
어떤 요청이 들어오면 잡을 처리하기위해 몇 개의 맵과 리듀스를 실행할지 계산한다.
이렇게 계산된 맵과 리듀스를 어떤 태스크트래커에서 실행할지 결정하고, 해당 태스크트래커에 잡을 할당한다.

태스크트래커
-사용자가 설정한 MapReduce프로그램을 실행하며, 하둡의 데이터노드에서 실행되는 데몬을 의미한다.
잡트래커의 작업을 요청받고, 잡트래커가 요청한 맵과 리듀스 개수만큼 맵태스크 및 리듀스태스크를 생성한다.
맵태스크와 리듀스태스크가 생성되면 새로운 JVM을 구동해 태스크들을 실행한다.
서버의 개수와 상관없이 여러 JVM을 실행해 데이터를 동시에 분석하므로 병렬처리작업에 문제가 없다.

2.2 데이터 플로우

2.2.1 맵 단계
첫 번째 단계는 입력 파일을 읽어 맵의 출력 데이터를 생성하는 맵 처리 단계다.
아래는 맵처리 단계를 나타내는 플로우다.

입력파일 -> 스플릿 -> 입력스플릿 -> 레코드읽기 -> 맵

스플릿
- MapReduce는 HDFS에 저장된 파일을 읽어서 배치처리를 한다.
이때 보통 HDFS에 저장된 데이터는 큰 규모의 데이터이다.
MapReduce 프레임워크는 이러한 대용량 파일을 처리하기 위해 입력 데이터 파일을 입력스플릿이라는 고정된 크기의 조각으로 분리한다.
이때 HDFS에 저장된 블록이 실제로 다시 분리되는 것은 아니고 가상으로 분리되는 것이다.
이렇게 입력스플릿을 생성하는 과정을 스플릿이라고 하며 스플릿별로 하나의 맵태스크가 생성된다.
또한 생성된 맵태스크에 입력데이터로 전달 된다.

레코드읽기
- 맵 태스크는 입력스플릿의 데이터를 레코드단위, 즉 한줄씩 읽어서 사용자가 정의한 맵함수를 실행한다.
이때 맵 태스크의 출력데이터는 태스크트래커가 실행되는 서버의 로컬디스크에 저장되며, 맵의 출력키 기준으로 정렬된다.
HDFS에 저장하지 않는 이유는 중간데이터이기 때문이고 잡이 완료될 경우 전부 삭제된다.

2.2.2 셔플
리듀스 태스크는 맵 태스크의 출력데이터를 내려받아 연산을 수행한다.
MapReduce 프레임워크는 이러한 작업이 진행될 수 있게 셔플을 지원합니다. 셔플은 맵 태스크의 출력데이터가 리듀스 태스크에게 전달되는 일련의 과정을 의미한다.
아래는 셔플을 나타내는 플로우이다.

맵 -> 파티셔닝 -> 파티셔너 -> 병합정렬 -> 중간파일 -> 레코드읽기 -> 리듀스

파티셔닝
- 파티셔너는 기본적으로 맵의 출력레코드를 읽어서 출력키의 해시값을 구한다.각 해시값은 레코드가 속하는 파티션번호로 사용된다.
하지만 사용자가 임의로 파티셔너를 개발해서 적용할 수도 있다.
파티션은 실행될 리듀스태스크의 개수만큼 생성된다.

병합정렬
- 파티셔닝된 맵의 출력데이터는 네트워크를 통해 리듀스태스크에 전달된다.
하지만 모든 맵태스크가 동시에 완료되는게 아니므로 리듀스태스크는 자신이 처리할 데이터가 다 모일때까지 대기한다.
리듀스 태스크는 맵의 출력 데이터가 모두 모이면 데이터를 정렬하고, 하나의 입력데이터로 병합한다.

레코드읽기
- 리듀스태스크는 병합된 데이터를 레코드단위로 읽어들인다.

2.2.3 리듀스 단계
리듀스단계는 사용자에게 전달할 출력파일을 생성한다.
아래는 리듀스 단계를 나타내는 플로우다.

리듀스 -> 출력 -> 출력파일

리듀스
- 리듀스태스크는 사용자가 정의한 리듀스 함수를 레코드 단위로 실행한다.
이때 리듀스태스크가 읽어들이는 데이터는 입력키와 입력키값의 목록으로 구성된다.

출력
리듀스함수가 출력한 데이터는 HDFS에 저장된다. 리듀스 개수만큼 출력파일이 생성된다.


2.3 프로그래밍 요소

2.3.1 데이터 타입
MapReduce는 네트워크 통신을 위한 최적화된 객체로 WritableComparable 인터페이스를 제공한다.
MapReduce의 Key, Value로 사용되는 데이터 타입은 전부 WritableComparable인터페이스가 구현되어 있어야 한다.
하둡에서 기본적인 데이터 타입은 제공해주지만 개발자가 직접 WritableComparable 인터페이스를 이용하여 구현할 수도 있다.

Writable
- write, readFields 메서드를 제공해주는 인터페이스이다.
write메서드의 경우 데이터값을 직렬화하는 역할을 하고 readFields메서드는 직렬화된 데이터를 해제해서 읽는 역할을 한다.
데이터 포맷 클래스는 이 두메서드를 구현하는 부분에서 데이터를 읽고 쓰는 기능을 처리한다.
Boolean -> BooleanWritable
단일 byte -> ByteWritable
Double -> DoubleWritable
Float -> FloatWritable
Integer -> IntWritable
Long -> LongWritable
문자열(UTF-8형식) -> TextWritable
데이터값이없을경우 -> NullWritable

Comparable
- java.lang 패키지의 인터페이스로 compareTo 메서드를 제공한다.

2.3.2 InputFormat
위의 2.2.1에서 얘기했듯이 입력파일이 들어오면 스플릿 과정을 통해 입력스플릿으로 만든다.
그리고 만들어진 입력스플릿을 Map단계의 입력값으로 사용을한다.
InputFormat은 추상클래스로서 map메서드의 입력파라미터로 사용할 수 있게 만드는 역할을 한다.
getSplit, createRecordReader 메서드를 제공한다.

getSplit
-입력 스플릿을 map메서드가 사용할 수 있게 해주는 메서드이다.

createRecordReader
- 위의 2.2.1에서 얘기했듯이 입력스플릿을 레코드읽기라는 과정을 통해 map메서드에서 입력파라미터로 사용된다.
이 메서드는 map메서드가 입력스플릿을 키와 목록의 형태로 사용할 수 있게 RecordReader라는 객체를 생성한다.
TextInputFormat - 텍스트파일을 분석할 때 사용하며 개행문자(\n)를 기준으로 레코드를 구분한다. Key는 라인번호이며 LongWritable, Value는 라인내용이며 Text타입.
KeyValueTextInputFormat - 텍스트파일을 분석할 때 라인번호가 아닌 임의의 키값을 지정해 사용할때 사용한다.
NLineInputFormat - 맵태스크가 입력받을 텍스트파일의 라인수를 제한할 때 사용한다.
DelegatingInputFormat - 여러개의 서로 다른 입력포맷을 사용하는 경우에 각 경로에 대한 작업을 위임할때 사용한다.
CombineFileInputFormat - 위에 나온 InputFormat들은 파일당 스플릿을 생성하지만 CombineFileInputFormat은 여러 개의 파일을 스플릿으로 묶어서 사용한다

2.3.3 매퍼
매퍼는 MapReduce에서 map메서드의 기능을 수행한다.
매퍼는 Key와 Value로 구성된 입력데이터를 전달받아 가공하고 분류해 새로운 데이터 목록을 생성한다.
위에서 계속 얘기해왔던 맵태스크가 매퍼클래스를 의미한다.
매퍼클래스는 기본적으로 제공되어 그대로 사용할 수 있지만 보통은 사용하려는 목적에 따라 구현하여 사용한다.
매퍼클래스의 경우 제네릭 파라미터를 사용해 클래스를 정의한다.
public class Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT>
KEYIN - 입력키유형, VALUEIN - 입력값유형, KEYOUT - 출력키유형, VALUEOUT - 출력값유형
매퍼클래스는 MapContext를 상속받은 Context객체를 생성한다.
생성된 context객체를 통해 job에 대한 정보를 얻어오고, 입력스플릿을 레코드단위로 읽는다.
기본 Mapper클래스의 Context생성구문에서 RecordReader<KEYIN, VALUEIN> reader라는 파라미터를 받는데 2.3.2의 InputFormat에서 얘기했듯이 입력스플릿이 Key와 Value로 전달되는거다.

매퍼클래스의 동작방식은
while (context.nextKeyValue()) {
    map(context.getCurrentKey(), context.getCurrentValue(), context);
}
와 같이 동작한다.
따라서 MapReduce프로그램을 개발할 때 대부분 map메서드를 재정의하여 자기가 원하는 동작을 시킨다.

2.3.4 파티셔너
파티셔너는 맵태스크의 출력데이터가 어떤 리듀스태스크로 전달될지 결정하는 역할을 한다.
추상클래스인 Partitioner클래스를 상속받아 getPartition메서드를 재정의해 사용할 수 있다.
기본적으로 HashPartitioner를 사용한다.

2.3.5 리듀서
리듀서클래스에서는 맵태스크의 출력데이터를 입력데이터로 전달받아 집계 연산을 수행한다.
리듀서클래스에서는 제네릭타입의 파라미터를 정의한다.
public class Reducer<KEYIN, VALUEIN, KEYOUT, VALUEOUT>
KEYIN - 입력키유형, VALUEIN - 입력값유형, KEYOUT - 출력키유형, VALUEOUT - 출력값유형
리듀서클래스도 2.3.3의 매퍼클래스처럼 Context객체를 선언하는데 이 객체는 ReduceContext를 상속받는다.
또한 매퍼클래스에서 map메서드를 재정의하여 사용했듯이 reduce라는 메서드를 재정의하여 사용한다.

2.3.6 콤바이너클래스
콤바이너 클래스가 뭔지 알기 전에 셔플이라는걸 먼저 알아봐야한다.

셔플
- 맵태스크에서 나온 출력데이터는 네트워크를 통해 리듀스태스크로 전달된다.
이 전달과정을 셔플이라고 표현한다.
네트워크를 통한 전달이기 때문에 전송할 데이터의 크기를 줄일수록 잡의 성능은 올라간다.

콤바이너클래스는 셔플에 이용되는 데이터의 크기를 줄이는데 도움이되는 클래스이다.
콤바이너클래스는 매퍼의 출력데이터를 입력데이터로 받아 연산을 수행한다.
로컬에 생성된 데이터를 이용하기때문에 네트워크 비용은 발생하지않는다.
콤바이너는 연산 후 리듀스태스크에 네트워크로 데이터를 전달한다.
지금까지 맵태스크 -> 출력데이터 -> 리듀스태스크 라고 알고있었는데 실제로 맵태스크 -> 출력데이터 -> 콤바이너클래스 -> 연산후 나온 데이터 -> 리듀스태스크의 흐름으로 실행될 수 있다.
따라서 콤바이너클래스의 연산을 효율적으로하여 데이터의 크기를 줄이면 효율적인 Job이 될 수 있다.
하지만 콤바이너클래스를 이용했을때나 이용하지않았을때나 출력결과는 같아야한다.( 성능을 위해서만 사용이 되는 클래스 )

2.3.7 OutputFormat
MapReduceJob의 출력데이터는 setOutputFormatClass메서드로 설정한 포맷대로 만들어집니다.
이때 사용하는 출력데이터 포맷은 OutputFormat이라는 추상 클래스를 상속받아 구현된다.
개발자가 별도로 OuputFormatClass를 지정하지 않은 경우 TextOutputFormat을 기본 포맷으로 설정한다.

