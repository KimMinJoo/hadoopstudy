HADOOP STUDY

프로그램 실행법

./bin/hadoop jar WordCountMapReduce.jar com.naver.Main input파일 output파일

MapReduce

MapReduce개념
MapReduce는 HDFS에 저장된 파일을 분산 배치 분석을 할 수 있도록 도와주는 분산 프레임워크.
개발자는 프로그래밍모델에 맞게 애플리케이션을 구현만 하면 된다.
나머지 데이터 전송, 분산 처리, 내고장성등의 복잡한 처리는 MapReduce프레임워크가 처리해준다.
MapReduce는 Map과 Reduce 두 단계로 데이터를 처리한다.

1. Map
Map 단계는 입력받은 데이터(ex - HDFS의 파일)를  Key, Value의 형태로 데이터를 분류하는 단계다.
기본적인 방식을 표현한다면 아래와 같다.
(K1, V1) -> list(K2, V2)

Ex.
입력 파일
read a book
write a book
두줄로 이루어진 txt파일.

첫번째라인, read a book -> {"read" : 1, "a" : 1, "book" : 1}
두번째라인 , write a book -> {"write" : 1, "a" : 1, "book" : 1}

2.Reduce
Map 단계에 나온 출력을 집계하는 단계입니다. 출력은 Key, Value의 형태입니다.
기본적인 방식을 표현한다면 아래와 같습니다.
(K2, list(V2)) -> (K3, list(V3))

위의 Map예제에서 이어서 보겠습니다.
Ex.
{"read" : 1, "a" : 1, "book" : 1}, {"write" : 1, "a" : 1, "book" : 1} -> {"a" : 2, "book" : 2, "read" : 1, "write" : 1}

2. Architecture
MapReduce 프레임 워크의 경우 개발자가 분석로직에만 집중할 수 있도록 해주고 다른 작업은 프레임워크에서 맡아서 해준다.
따라서 시스템 구성 및 데이터 흐름을 모르더라도 당장의 개발에 지장이 없다.
하지만 시스템 구성 및 데이터 흐름을 모르고 개발한다면 성능을 고려하지 못한 개발을 할 수 밖에 없으며 문제가 생길 경우
해결할 수 없다.

2.1 시스템 구성
MapReduce 시스템은 클라이언트, 잡트래커, 태스크트래커로 구성된다.
클라이언트 <-> 잡트래커간의 일은 클라이언트가 잡트래커에 잡 실행을 요청하면 잡트래커가 잡을 실행하여 진행상황 및 결과를 공유해준다.
잡트래커 <-> 태스크트래커간의 일은 아래에 설명한다.
먼저 잡트래커가 태스크트래커에게 태스크실행을 요청한다.
그럼 태스크 트래커는 잡트래커가 요청한 맵과 리듀스 갯수만큼 맵태스크와 리듀스태스크를 생성한다.
태스크가 생성이 되면 새로운 JVM을 구동해 태스크들을 실행한다.
잡트래커와 태스크트래커는 하트비트라는 메서드로 네트워크 통신을 하면서 태스크트래커의 상태와 작업실행정보를 주고받게된다.
만약 태스크트래커에 장애가 발생한다면  다른 대기중인 태스크트래커를 찾아서 재실행한다.

클라이언트
-사용자가 실행한 MapReduce프로그램과 하둡에서 제공하는 MapReduceAPI를 의미

잡
-클라이언트가 하둡으로 실행을 요청하는 맵리듀스 프로그램을 관리하는 작업 단위

잡트래커
-하둡클러스터에 등록된 전체 잡의 스케줄링을 관리하고 모니터링한다.
어떤 요청이 들어오면 잡을 처리하기위해 몇 개의 맵과 리듀스를 실행할지 계산한다.
이렇게 계산된 맵과 리듀스를 어떤 태스크트래커에서 실행할지 결정하고, 해당 태스크트래커에 잡을 할당한다.

태스크트래커
-사용자가 설정한 MapReduce프로그램을 실행하며, 하둡의 데이터노드에서 실행되는 데몬을 의미한다.
잡트래커의 작업을 요청받고, 잡트래커가 요청한 맵과 리듀스 개수만큼 맵태스크 및 리듀스태스크를 생성한다.
맵태스크와 리듀스태스크가 생성되면 새로운 JVM을 구동해 태스크들을 실행한다.
서버의 개수와 상관없이 여러 JVM을 실행해 데이터를 동시에 분석하므로 병렬처리작업에 문제가 없다.

2.2 데이터 플로우

2.2.1 맵 단계
첫 번째 단계는 입력 파일을 읽어 맵의 출력 데이터를 생성하는 맵 처리 단계다.
아래는 맵처리 단계를 나타내는 플로우다.

입력파일 -> 스플릿 -> 입력스플릿 -> 레코드읽기 -> 맵

스플릿
- MapReduce는 HDFS에 저장된 파일을 읽어서 배치처리를 한다.
이때 보통 HDFS에 저장된 데이터는 큰 규모의 데이터이다.
MapReduce 프레임워크는 이러한 대용량 파일을 처리하기 위해 입력 데이터 파일을 입력스플릿이라는 고정된 크기의 조각으로 분리한다.
이때 HDFS에 저장된 블록이 실제로 다시 분리되는 것은 아니고 가상으로 분리되는 것이다.
이렇게 입력스플릿을 생성하는 과정을 스플릿이라고 하며 스플릿별로 하나의 맵태스크가 생성된다.
또한 생성된 맵태스크에 입력데이터로 전달 된다.

레코드읽기
- 맵 태스크는 입력스플릿의 데이터를 레코드단위, 즉 한줄씩 읽어서 사용자가 정의한 맵함수를 실행한다.
이때 맵 태스크의 출력데이터는 태스크트래커가 실행되는 서버의 로컬디스크에 저장되며, 맵의 출력키 기준으로 정렬된다.
HDFS에 저장하지 않는 이유는 중간데이터이기 때문이고 잡이 완료될 경우 전부 삭제된다.

2.2.2 셔플
리듀스 태스크는 맵 태스크의 출력데이터를 내려받아 연산을 수행한다.
MapReduce 프레임워크는 이러한 작업이 진행될 수 있게 셔플을 지원합니다. 셔플은 맵 태스크의 출력데이터가 리듀스 태스크에게 전달되는 일련의 과정을 의미한다.
아래는 셔플을 나타내는 플로우이다.

맵 -> 파티셔닝 -> 파티셔너 -> 병합정렬 -> 중간파일 -> 레코드읽기 -> 리듀스

파티셔닝
- 파티셔너는 기본적으로 맵의 출력레코드를 읽어서 출력키의 해시값을 구한다.각 해시값은 레코드가 속하는 파티션번호로 사용된다.
하지만 사용자가 임의로 파티셔너를 개발해서 적용할 수도 있다.
파티션은 실행될 리듀스태스크의 개수만큼 생성된다.

병합정렬
- 파티셔닝된 맵의 출력데이터는 네트워크를 통해 리듀스태스크에 전달된다.
하지만 모든 맵태스크가 동시에 완료되는게 아니므로 리듀스태스크는 자신이 처리할 데이터가 다 모일때까지 대기한다.
리듀스 태스크는 맵의 출력 데이터가 모두 모이면 데이터를 정렬하고, 하나의 입력데이터로 병합한다.

레코드읽기
- 리듀스태스크는 병합된 데이터를 레코드단위로 읽어들인다.

2.2.3 리듀스 단계
리듀스단계는 사용자에게 전달할 출력파일을 생성한다.
아래는 리듀스 단계를 나타내는 플로우다.

리듀스 -> 출력 -> 출력파일

리듀스
- 리듀스태스크는 사용자가 정의한 리듀스 함수를 레코드 단위로 실행한다.
이때 리듀스태스크가 읽어들이는 데이터는 입력키와 입력키값의 목록으로 구성된다.

출력
리듀스함수가 출력한 데이터는 HDFS에 저장된다. 리듀스 개수만큼 출력파일이 생성된다.
